





:class:`hdf5dpf_workglow_provider`
==================================

.. py:class:: ansys.dpf.core.operators.utility.hdf5dpf_workglow_provider.hdf5dpf_workglow_provider(time_scoping=None, mesh_scoping=None, streams=None, data_sources=None, meta_data=None, result_name=None, config=None, server=None)

   Bases: :py:obj:`ansys.dpf.core.dpf_operator.Operator`


   Extract a custom result from an hdf5dpf file as an executable
   workflow.

   :param time_scoping:
   :type time_scoping: Scoping, optional
   :param mesh_scoping:
   :type mesh_scoping: Scoping, optional
   :param streams: Hdf5df file stream.
   :type streams: StreamsContainer, optional
   :param data_sources: Hdf5df file data source.
   :type data_sources: DataSources, optional
   :param meta_data: Meta_data that may be used to evaluate
                     results or extract workflows.
   :type meta_data: DataTree, optional
   :param result_name: Name of the result that must be extracted
                       from the hdf5dpf file

   :returns: **field_or_fields_container**
   :rtype: Workflow

   .. rubric:: Examples

   >>> from ansys.dpf import core as dpf

   >>> # Instantiate operator
   >>> op = dpf.operators.utility.hdf5dpf_workglow_provider()

   >>> # Make input connections
   >>> my_time_scoping = dpf.Scoping()
   >>> op.inputs.time_scoping.connect(my_time_scoping)
   >>> my_mesh_scoping = dpf.Scoping()
   >>> op.inputs.mesh_scoping.connect(my_mesh_scoping)
   >>> my_streams = dpf.StreamsContainer()
   >>> op.inputs.streams.connect(my_streams)
   >>> my_data_sources = dpf.DataSources()
   >>> op.inputs.data_sources.connect(my_data_sources)
   >>> my_meta_data = dpf.DataTree()
   >>> op.inputs.meta_data.connect(my_meta_data)
   >>> my_result_name = dpf.()
   >>> op.inputs.result_name.connect(my_result_name)

   >>> # Instantiate operator and connect inputs in one line
   >>> op = dpf.operators.utility.hdf5dpf_workglow_provider(
   ...     time_scoping=my_time_scoping,
   ...     mesh_scoping=my_mesh_scoping,
   ...     streams=my_streams,
   ...     data_sources=my_data_sources,
   ...     meta_data=my_meta_data,
   ...     result_name=my_result_name,
   ... )

   >>> # Get output data
   >>> result_field_or_fields_container = op.outputs.field_or_fields_container()




.. py:currentmodule:: hdf5dpf_workglow_provider

Overview
--------

.. tab-set::




   .. tab-item:: Properties

      .. list-table::
          :header-rows: 0
          :widths: auto

          * - :py:attr:`~inputs`
            - Enables to connect inputs to the operator
          * - :py:attr:`~outputs`
            - Enables to get outputs of the operator by evaluating it



   .. tab-item:: Static methods

      .. list-table::
          :header-rows: 0
          :widths: auto

          * - :py:attr:`~default_config`
            - Returns the default config of the operator.





Import detail
-------------

.. code-block:: python

    from ansys.dpf.core.operators.utility.hdf5dpf_workglow_provider import hdf5dpf_workglow_provider

Property detail
---------------

.. py:property:: inputs

   Enables to connect inputs to the operator

   :returns: **inputs**
   :rtype: InputsHdf5DpfWorkglowProvider

.. py:property:: outputs

   Enables to get outputs of the operator by evaluating it

   :returns: **outputs**
   :rtype: OutputsHdf5DpfWorkglowProvider




Method detail
-------------

.. py:method:: default_config(server=None)
   :staticmethod:


   Returns the default config of the operator.

   This config can then be changed to the user needs and be used to
   instantiate the operator. The Configuration allows to customize
   how the operation will be processed by the operator.

   :param server: Server with channel connected to the remote or local instance. When
                  ``None``, attempts to use the global server.
   :type server: server.DPFServer, optional





